# Multiple Linear Regression Models

## Required packages

The following CRAN packages must be installed:

| Required CRAN Packages |
|------------------------|
| tidyverse              |
| usethis                |
| janitor                |
| skimr                  |
| apaTables              |
| broom                  |
| corrr                  |
| tidymodels             |
| psych                  |


REMINDER: Never use the command library(psych).

```{r}
#| include: false
library(tidyverse)
library(usethis) # use_github_file() 
library(janitor) # clean_names() 
library(skimr) # skim()
library(apaTables)
library(broom)
library(tidymodels)
library(corrr)
```

## Page 66 Correlations

### Activate packages

```{r}
library(usethis) # use_github_file()
library(tidyverse) # read_csv() 
library(janitor) # clean_names() 
```

### Obtain data and save it to your computer

```{r}
#| include: false
use_github_file(repo_spec = "https://github.com/johnhoffmannVA/LinearRegression/blob/main/StateData2018.csv",
                save_as = "statedata2018.csv")

statedata2018 <- read_csv("statedata2018.csv", show_col_types = FALSE) %>% clean_names()
```

```{r}
#| eval: false
use_github_file(repo_spec = "https://github.com/johnhoffmannVA/LinearRegression/blob/main/StateData2018.csv",
                save_as = "statedata2018.csv")
```

#### Load data from your computer

Clean names is essential here. It makes sure all column names are lower case. They are not all lower case in the original data file.

```{r}
#| eval: false
statedata2018 <- read_csv("statedata2018.csv") %>% 
  clean_names()
```

### Inspect data

There are so many column names in this data set that we do the glimpse a bit differently. That is, we sort the order of the columns alphabetically prior to doing the glimpse(). It affects only the display of the column names - not the structure of the data.

```{r}
statedata2018 %>% 
  select(sort(names(statedata2018))) %>%
  glimpse()  
```

### Select focal variables

```{r}
focal_data <- statedata2018 %>%
  select(violent_crime_rate, per_child_poverty, med_hh_income)
```

### Select focal variables

```{r}
library(corrr)

focal_data %>% 
  correlate()
```

### Correlation options

#### psych package

```{r}
focal_data %>% 
  psych::corr.test()
```

#### apaTables package

```{r}
library(apaTables)

focal_data %>% 
  apa.cor.table()
```

#### corrr package

We use correlate() to get the correlations, shave() to remove upper diagonal, and fashion() to make it nice:

```{r}
#| message: false
library(corrr)

focal_data %>% 
  correlate() %>%
  shave() %>%
  fashion()
```

But more importantly the corr package has network_plot() to visual relations among variables. Here we only plot relations where the magnitude of the correlation is greater than .20:

```{r}
#| message: false
#| warning: false
#| 
focal_data %>% 
  correlate() %>%
  network_plot(min_cor = .2,
               colors = c("red", "green"), 
               legend = "full")
```

## Page 67 One Predictor

```{r}
#| eval: false
lm4_1 <- lm(violent_crime_rate ~ per_child_poverty + med_hh_income,
            data = focal_data)

apa.reg.table(lm4_1)

```

```{r}
#| echo: false
lm4_1 <- lm(violent_crime_rate ~ per_child_poverty,
            data = focal_data)

knitr::kable(apa.reg.table(lm4_1)$latex.body)
```

## Page 68 Two Predictors

```{r}
#| eval: false
lm4_2 <- lm(violent_crime_rate ~ per_child_poverty + med_hh_income,
            data = focal_data)

apa.reg.table(lm4_2)

```

```{r}
#| echo: false
lm4_2 <- lm(violent_crime_rate ~ per_child_poverty + med_hh_income,
            data = focal_data)

knitr::kable(apa.reg.table(lm4_2)$latex.body)
```

### Two Predictors: Predicted Scores

Two help us interpret the data we will make a graph. But to do so we need to know the range for per_child_poverty. We find it ranges from 9 percent to 28 percent from the skim() output below.

```{r}
focal_data %>%
  select(per_child_poverty) %>%
  skim()
```

Now we want to know the mean of med_hh_income. We find it is 60252.

```{r}
focal_data %>%
  select(per_child_poverty) %>%
  skim()
```

Now we want to HOLD med_hh_income constant at 60252 see how violent_crime_rate changes with per_child_poverty. We create a dataset where this is the case:

```{r}

predict4values <- data.frame(per_child_poverty = seq(9, 28), 
                             med_hh_income = 60252)

print(predict4values)
```

We use our regression model to generate predicted scores:

```{r}

# Create predicted scores use the regression weights created in lm4_2
predicted_violent_crime_rate <- predict(lm4_2, 
                                        newdata = predict4values)

# Put the predicted scores back into our data set of possible values
predict4values <- predict4values %>%
  mutate(predicted_violent_crime_rate = predicted_violent_crime_rate)
  

print(predict4values)  
```

Now graph it:

```{r}
prediction_graph <- ggplot(data = predict4values,
                           mapping = aes(x = per_child_poverty,
                                         y = predicted_violent_crime_rate)) +
  geom_line(linewidth = 2) +
  coord_cartesian(xlim = c(9, 28), ylim = c(100, 700)) +
  scale_x_continuous(breaks = seq(10, 25, by = 5)) +
  scale_y_continuous(breaks = seq(100, 700, by = 100)) +
  theme_light() +
  labs(x = "Perecent Child Poverty",
       y = "Predicted Violent Crime Rate (yhat)")

print(prediction_graph)
```

## Page 71 3D plot

When you have two predictors you don't have a regression line - you have a regression surface. The code below creates a surface plot that you can interact with/rotate/etc. Note that even though we put med_hh_income in the moderator position in the function there is no moderation here.

```{r}
#| warning: false
#| message: false

library(fastInteraction)

surface_plot <- fast.plot(lm4_2,
                          criterion = violent_crime_rate,
                          predictor = med_hh_income,
                          moderator = per_child_poverty)

surface_plot
```

## Page 72 Understanding b-weights

See the original regression below. Notice the b-weight (the unstandardized regression weight) for per_child_poverty is 21.1797652. We are going to try to recreate this value in another way to make it clear what it means.

```{r}
#| eval: false


# Original regression
lm4_2 <- lm(violent_crime_rate ~ per_child_poverty + med_hh_income,
            data = focal_data)

tidy(lm4_2)

```

```{r}
#| echo: false


# Original regression
lm4_2 <- lm(violent_crime_rate ~ per_child_poverty + med_hh_income,
            data = focal_data)

knitr::kable(tidy(lm4_2))

```

First, we create a residualized version of violent_crime_rate.  That is, a version of violent_crime_rate has teh effect of med_hh_income removed from it. We use the residual() command. This is the same as getting the value from the .resid column after using the augment() command.

```{r}
library(tidymodels)

lm_violent_crime_rate <- lm(violent_crime_rate ~ med_hh_income, data = focal_data)
violent_crime_rate_residual <- lm_violent_crime_rate$residuals
```

Second, we create a residualized version of per_child_poverty. That is, a version of per_child_poverty has teh effect of med_hh_income removed from it.

```{r}
lm_per_child_poverty <- lm(per_child_poverty ~  med_hh_income, data = focal_data)
per_child_poverty_residual <- lm_per_child_poverty$residuals
```

To get the b-weight or the original regression (lm4_2) for per_child_poverty we conduct a bivariate regression with these two residuals.

```{r}
#| eval: false

lm_bweight_demo <- lm(violent_crime_rate_residual ~ per_child_poverty_residual)

tidy(lm_bweight_demo)
```

```{r}
#| echo: false

lm_bweight_demo <- lm(violent_crime_rate_residual ~ per_child_poverty_residual)

knitr::kable(tidy(lm_bweight_demo))
```

Notice that we get 21.1797652 as the b-weight for per_child_poverty_residual here. This is the same as the b-weight for per_child_poverty (no residual suffix) in the original regression lm4_2.  The diagram beloow illustrate that b-weight are weights based on residualized verions of a predictor and the criterion.

```{r}
#| echo: false
#| out.width: 70%

knitr::include_graphics("ch_4/partial-b-weight.png")
```

## Page 76 Understanding b- vs beta-weights

## Page 77 Relative importance

## Page 79 Predicted Means

## Page 86 Chapter Exercises

### Activate packages

```{r}
library(usethis) # use_github_file()
library(tidyverse) # read_csv() 
library(janitor) # clean_names() 
```

### Obtain data and save it to your computer

```{r}
#| include: false
use_github_file(repo_spec = "https://github.com/johnhoffmannVA/LinearRegression/blob/main/TeenBirths.csv",
                save_as = "teenbirths.csv")

teenbirths <- read_csv("teenbirths.csv", show_col_types = FALSE) %>% clean_names()
```

```{r}
#| eval: false
use_github_file(repo_spec = "https://github.com/johnhoffmannVA/LinearRegression/blob/main/TeenBirths.csv",
                save_as = "teenbirths.csv")
```

### Load data from your computer

```{r}
#| eval: false
teenbirths <- read_csv("teenbirths.csv") %>% 
  clean_names()
```

### Inspect data

```{r}
teenbirths %>% 
  glimpse()  
```

```{r}
teenbirths <- teenbirths %>% 
  mutate(state = as_factor(state)) %>%
  mutate(county = as_factor(county))
```

```{r}
teenbirths %>% 
  glimpse()  
```

```{r}
teenbirths %>% 
  skim()  
```
