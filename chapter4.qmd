# Multiple Linear Regression Models

## Required packages

The following CRAN packages must be installed:

| Required CRAN Packages |
|------------------------|
| tidyverse              |
| usethis                |
| janitor                |
| skimr                  |
| apaTables              |
| broom                  |
| corrr                  |
| tidymodels             |
| remotes                |
| relaimpo               |
| psych                  |

REMINDER:

Never use the command library(psych). Instead use psych:: before each command.

Never use the command library(relaimpo). Instead use relaimpo:: before each command.

The following GitHub packages must be installed:

| Required GitHub Packages  |
|---------------------------|
| dstanley4/fastInteraction |

After the remotes package is installed, it can be used to install a package from GitHub:

```{r}
#| eval: false
remotes::install_github("dstanley4/fastInteraction")
```

```{r}
#| include: false
library(tidyverse)
library(usethis) # use_github_file() 
library(janitor) # clean_names() 
library(skimr) # skim()
library(apaTables)
library(broom)
library(tidymodels)
library(corrr)
```

## Page 66 Correlations

### Activate packages

```{r}
library(usethis) # use_github_file()
library(tidyverse) # read_csv() 
library(janitor) # clean_names() 
```

### Obtain data and save it to your computer

```{r}
#| include: false
use_github_file(repo_spec = "https://github.com/johnhoffmannVA/LinearRegression/blob/main/StateData2018.csv",
                save_as = "statedata2018.csv")

statedata2018 <- read_csv("statedata2018.csv", show_col_types = FALSE) %>% clean_names()
```

```{r}
#| eval: false
use_github_file(repo_spec = "https://github.com/johnhoffmannVA/LinearRegression/blob/main/StateData2018.csv",
                save_as = "statedata2018.csv")
```

#### Load data from your computer

Clean names is essential here. It makes sure all column names are lower case. They are not all lower case in the original data file.

```{r}
#| eval: false
statedata2018 <- read_csv("statedata2018.csv") %>% 
  clean_names()
```

### Inspect data

There are so many column names in this data set that we do the glimpse a bit differently. That is, we sort the order of the columns alphabetically prior to doing the glimpse(). It affects only the display of the column names - not the structure of the data.

```{r}
statedata2018 %>% 
  select(sort(names(statedata2018))) %>%
  glimpse()  
```

### Select focal variables

```{r}
focal_data <- statedata2018 %>%
  select(violent_crime_rate, per_child_poverty, med_hh_income)
```

### Correlation options

#### psych package

```{r}
focal_data %>% 
  psych::corr.test()
```

#### apaTables package

```{r}
library(apaTables)

focal_data %>% 
  apa.cor.table()
```

#### corrr package

We use correlate() to get the correlations, shave() to remove upper diagonal, and fashion() to make it nice:

```{r}
#| message: false
library(corrr)

focal_data %>% 
  correlate() %>%
  shave() %>%
  fashion()
```

But more importantly the corrr package has network_plot() to visual relations among variables. Here we only plot relations where the magnitude of the correlation is greater than .20:

```{r}
#| message: false
#| warning: false
#| 
focal_data %>% 
  correlate() %>%
  network_plot(min_cor = .2,
               colors = c("red", "green"), 
               legend = "full")
```

## Page 67 One Predictor

```{r}
#| eval: true
lm4_1 <- lm(violent_crime_rate ~ per_child_poverty,
            data = focal_data)

tidy(lm4_1)

```

## Page 68 Two Predictors

```{r}
#| eval: true
lm4_2 <- lm(violent_crime_rate ~ per_child_poverty + med_hh_income,
            data = focal_data)

tidy(lm4_2)

```

### Two Predictors: Predicted Scores

Two help us interpret the data we will make a graph. But to do so we need to know the range for per_child_poverty. We find it ranges from 9 percent to 28 percent from the skim() output below.

```{r}
focal_data %>%
  select(per_child_poverty) %>%
  skim()
```

Now we want to know the mean of med_hh_income below. We find it is 60252.

```{r}
focal_data %>%
  select(med_hh_income) %>%
  skim()
```

Now we want to HOLD med_hh_income constant at 60252 and then see how violent_crime_rate changes with per_child_poverty. We create a dataset where this is the case:

```{r}

predict4values <- data.frame(per_child_poverty = seq(9, 28), 
                             med_hh_income = 60252)

print(predict4values)
```

We use our regression model to generate predicted scores:

```{r}

# Create predicted scores use the regression weights created in lm4_2
predicted_violent_crime_rate <- stats::predict(lm4_2, 
                                        newdata = predict4values)

# Put the predicted scores back into our data set of possible values
predict4values <- predict4values %>%
  mutate(predicted_violent_crime_rate = predicted_violent_crime_rate)
  

print(predict4values)  
```

Now graph it:

```{r}
prediction_graph <- ggplot(data = predict4values,
                           mapping = aes(x = per_child_poverty,
                                         y = predicted_violent_crime_rate)) +
  geom_line(linewidth = 2) +
  coord_cartesian(xlim = c(9, 28), ylim = c(100, 700)) +
  scale_x_continuous(breaks = seq(10, 25, by = 5)) +
  scale_y_continuous(breaks = seq(100, 700, by = 100)) +
  theme_light() +
  labs(x = "Percent Child Poverty",
       y = "Predicted Violent Crime Rate (yhat)")

print(prediction_graph)
```

## Page 71 3D plot

When you have two predictors you don't have a regression line - you have a regression surface. The code below creates a surface plot that you can interact with/rotate/etc. Note that even though we put med_hh_income in the moderator position in the function there is no moderation here. Be sure to click and drag to rotate the graph.

```{r}
#| warning: false
#| message: false

library(fastInteraction)

surface_plot <- fast.plot(lm4_2,
                          criterion = violent_crime_rate,
                          predictor = med_hh_income,
                          moderator = per_child_poverty)

surface_plot
```

## Page 72 Understanding b-weights

See the original regression below. Notice the b-weight (the unstandardized regression weight) for per_child_poverty is 21.1797652. We are going to try to recreate this value in another way to make it clear what it means.

```{r}
#| eval: true


# Original regression
lm4_2 <- lm(violent_crime_rate ~ per_child_poverty + med_hh_income,
            data = focal_data)

tidy(lm4_2)

```

First, we create a residualized version of violent_crime_rate. That is, a version of violent_crime_rate has teh effect of med_hh_income removed from it. We use the residual() command. This is the same as getting the value from the .resid column after using the augment() command.

```{r}
library(tidymodels)

lm_violent_crime_rate <- lm(violent_crime_rate ~ med_hh_income, data = focal_data)
violent_crime_rate_residual <- lm_violent_crime_rate$residuals
```

Second, we create a residualized version of per_child_poverty. That is, a version of per_child_poverty has teh effect of med_hh_income removed from it.

```{r}
lm_per_child_poverty <- lm(per_child_poverty ~  med_hh_income, data = focal_data)
per_child_poverty_residual <- lm_per_child_poverty$residuals
```

To get the b-weight or the original regression (lm4_2) for per_child_poverty we conduct a bivariate regression with these two residuals.

```{r}
#| eval: true

lm_bweight_demo <- lm(violent_crime_rate_residual ~ per_child_poverty_residual)

tidy(lm_bweight_demo)
```

Notice that we get 21.1797652 as the b-weight for per_child_poverty_residual here. This is the same as the b-weight for per_child_poverty (no residual suffix) in the original regression lm4_2. The diagram beloow illustrate that b-weight in a multiple regression are weights based on residualized verions of a predictor and the criterion.

```{r}
#| echo: false
#| out.width: 70%

knitr::include_graphics("ch_4/partial-b-weight.png")
```

## Page 76 b- vs beta-weights

The regression weights that we have looked at so far - are usually referred to as b-weights or unstandardized regression coefficients. The are obtained when we analyze the data in it's original form. That is, each variable has. a different mean and standard deviation. Sometimes, however, we want to be able to compare the magnitude of regression weights. To do so, we need to set the mean of each variable (predictor or criterion) to zero prior to analysis. As well, we need to set the standard deviation of each variable prior to analysis. That is, we need to standrdized (M=0, SD =1) each variable prior to analysis. The weights we obtain when we do this are referred to as beta-weights or standardized regression cofficients. A better name, not used, would be regression weights for standardized data. We can obtain this weights by analyzing the data as described or by transforming b-weights using the formula in the textboook. Standardized regression weights (beta-weights) can be obtained using the apa.reg.table() command in the apaTables package.

```{r}
#| eval: false

lm4_3 <- lm(violent_crime_rate ~ per_child_poverty + med_hh_income,
            data = focal_data)

table1 = apa.reg.table(lm4_3, table.number = 1)

apa.save("table1.doc", table1)

```

## Page 77 Relative importance

```{r}
#| eval: true

# It's always a good idea to get the set of focal variables 
# in a separate data set.  Once you have missing data,
# this approach is critical.
focal_data <- statedata2018 %>%
  select(violent_crime_rate, 
         per_child_poverty, 
         med_hh_income, 
         unemploy_rate,
         percent_uninsured)

lm4_4 <- lm(violent_crime_rate ~ per_child_poverty + 
              med_hh_income + unemploy_rate + percent_uninsured,
            data = focal_data)

tidy(lm4_4)
```

Then you can obtain relative importance information:

```{r}

x_compare <- relaimpo::calc.relimp(lm4_4, 
                         type = c("lmg",
                                  "first", 
                                  "last", 
                                  "betasq", 
                                  "pratt"))
print(x_compare)
```

Then make the plots:

```{r}
plot(x_compare)
```

## Page 79 Predicted Means

Recall the regression:

```{r}
focal_data <- statedata2018 %>%
  select(violent_crime_rate, 
         per_child_poverty, 
         med_hh_income)

lm4_3 <- lm(violent_crime_rate ~ per_child_poverty + med_hh_income,
            data = focal_data)

tidy(lm4_3)

```

We need the percentiles for per_child_poverty and med_hh_income.

```{r}
focal_data %>%
  select(per_child_poverty, med_hh_income) %>%
  skim()

```

For per_child_poverty: 25th percentile is 13, 75th percentile is 20. We want to look at these with reference to the 50th percentile of med_hh_income which is 59162.

```{r}
predict4values <- data.frame(per_child_poverty = c(13, 20),
                             med_hh_income = 59162.)

print(predict4values)

stats::predict(lm4_3, predict4values)
```

For med_hh_income: 25th percentile is 53134, 75th percentile is 67687 We want to look at these with reference to the 50th percentile of per_child_poverty which is 16.5

```{r}
predict4values <- data.frame(per_child_poverty = 16.5,
                             med_hh_income = c(53134, 67687))

print(predict4values)

stats::predict(lm4_3, predict4values)
```

## Page 86 Chapter Exercises

### Activate packages

```{r}
library(usethis) # use_github_file()
library(tidyverse) # read_csv() 
library(janitor) # clean_names() 
```

### Obtain data and save it to your computer

```{r}
#| include: false
use_github_file(repo_spec = "https://github.com/johnhoffmannVA/LinearRegression/blob/main/TeenBirths.csv",
                save_as = "teenbirths.csv")

teenbirths <- read_csv("teenbirths.csv", show_col_types = FALSE) %>% clean_names()
```

```{r}
#| eval: false
use_github_file(repo_spec = "https://github.com/johnhoffmannVA/LinearRegression/blob/main/TeenBirths.csv",
                save_as = "teenbirths.csv")
```

### Load data from your computer

```{r}
#| eval: false
teenbirths <- read_csv("teenbirths.csv") %>% 
  clean_names()
```

### Inspect data

```{r}
teenbirths %>% 
  glimpse()  
```

```{r}
teenbirths <- teenbirths %>% 
  mutate(state = as_factor(state)) %>%
  mutate(county = as_factor(county))
```

```{r}
teenbirths %>% 
  glimpse()  
```

```{r}
teenbirths %>% 
  skim()  
```
